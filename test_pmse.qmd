---
title: "Can the $pMSE$ detect missing relationships between variables?"
format: html
date: last-modified
author: Thom Benjamin Volker
---

The answer is "No; at least it's not very good".

# Properties $pMSE$ for CART, logistic regression and lasso regression

```{r}
#| message: false
#| warning: false
library(synthpop)
library(patchwork)
library(purrr)
library(dplyr)
library(glmnet)
library(ggplot2)
library(lfda)
```


## Generate data

### Three predictor variables

```{r}
set.seed(123)

N <- 500
r <- 0.5

P3 <- 3
M3 <- rep(0, P3)

SR3 <- matrix(r, P3, P3)
diag(SR3) <- 1

SS3 <- diag(P3)

XR3 <- rnorm(N*P3) |> matrix(N, P3) %*% chol(SR3)
XS3 <- rnorm(N*P3) |> matrix(N, P3) %*% chol(SS3)
```

### Ten predictor variables

```{r}
P10 <- 10
M10 <- rep(0, P10)

SR10 <- matrix(r, P10, P10)
diag(SR10) <- 1

SS10 <- diag(P10)

XR10 <- rnorm(N*P10) |> matrix(N, P10) %*% chol(SR10)
XS10 <- rnorm(N*P10) |> matrix(N, P10) %*% chol(SS10)
```

### Twenty predictor variables

```{r}
P20 <- 20
M20 <- rep(0, P20)

SR20 <- matrix(r, P20, P20)
diag(SR20) <- 1

SS20 <- diag(P20)

XR20 <- rnorm(N*P20) |> matrix(N, P20) %*% chol(SR20)
XS20 <- rnorm(N*P20) |> matrix(N, P20) %*% chol(SS20)
```

### Combine data sets

```{r}
XR <- list(XR3, XR10, XR20)
XS <- list(XS3, XS10, XS20)
```


## Compare real and synthetic data

```{r}
#| cache: true
#| message: false
CART <- map2_dbl(XR, XS,
                 ~synthpop::utility.gen(data.frame(.x),
                                        data.frame(.y),
                                        method = "cart",
                                        print.flag=F)$S_pMSE)


logistic <- map2_dbl(XR, XS,
                     ~synthpop::utility.gen(data.frame(.x),
                                            data.frame(.y),
                                            method = "logit",
                                            print.flag=F,
                                            maxorder = 1)$S_pMSE)

lasso <- map2_dbl(XR, XS,
                  function(real, synthetic) {
                    form <- paste0("Synthetic ~ .^3 + ", 
                                   paste0("I(X", 1:ncol(real), "^2)", collapse = " + "),
                                   " + ",
                                   paste0("I(X", 1:ncol(real), "^3)", collapse = " + "))
                    dat <- bind_rows(Real = data.frame(real),
                                     Synthetic = data.frame(synthetic),
                                    .id = "Synthetic")
                    X   <- model.matrix(as.formula(form), dat)[,-1]
                    Y   <- factor(dat$Synthetic)
                    mod <- cv.glmnet(x = X, y = Y, alpha = 1, family = "binomial")
                    p   <- predict(mod, newx = X, s = mod$lambda.min, type = "response")
                    mean((p-0.5)^2) / ((ncol(X))*0.5^3/nrow(X))
                  })

data.frame(CART = CART,
           Logistic = logistic,
           Lasso = lasso) |>
  knitr::kable() |>
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

So, we can conclude that the $pMSE$ is not very good at detecting missed relationships between variables, and the problem gets worse when the dimensionality of the data increases. Note that the estimates of the lasso are conservative, as the number of variables in the predictor matrix is chosen to be the number of parameters in the model (and thus shrinkage is not accounted for). Using a (probably) overly optimistic estimate (only the non-zero coefficients), the standardized $pMSE$ would be around $7$.

```{r}
map2(XR, XS, ~utility.tables(data.frame(.x), data.frame(.y)))
```

According to the figures, the same findings hold for two-way assessments of utility (i.e., for pairs of variables).

# Other techniques for assessing distributional similarity

## PCA dimension reduction

With Kolmogorov-Smirnov test on the first principal component

```{r}
pca <- function(real, synthetic) {
  X   <- rbind(real, synthetic) |> scale()
  USV <- svd(X)
  ID  <- rep(c("Real", "Synthetic"), times = c(nrow(real), nrow(synthetic)))
  data.frame(X %*% USV$v, ID) |>
    setNames(c(paste0("PC", 1:ncol(USV$v)), "Synthetic"))
}

map2(XR, XS, function(real, synthetic) {
       pca(real, synthetic) |>
         ggplot(aes(PC1, PC2, col = Synthetic)) +
         geom_point() +
         theme_minimal()
     }) |>
  patchwork::wrap_plots(ncol = 3, guides = "collect") &
  theme(legend.position = "bottom")

map2(XR, XS, function(real, synthetic) {
  D <- pca(real, synthetic)
  ks.test(D |> filter(Synthetic == "Real") |> pull(PC1),
          D |> filter(Synthetic == "Synthetic") |> pull(PC1))
})



map2(XR, XS, function(real, synthetic) {
  PC <- pca(real, synthetic)
  R <- PC |> filter(Synthetic == "Real")
  S <- PC |> filter(Synthetic == "Synthetic")
  
  Synthpop_S_pMSE <- utility.gen(R |> select(PC1, PC2),
                                 S |> select(PC1, PC2),
                                 method = "logit",
                                 maxorder = 1)$S_pMSE
  
  S_prop <- nrow(S) / nrow(PC)
  n_pMSE <- 5 * (1 - S_prop)^2 * S_prop / nrow(PC)
  Manual_S_pMSE <- PC |>
    select(PC1, PC2, Synthetic) |>
    glm(formula = factor(Synthetic) ~ PC1 + PC2 + PC1:PC2 + I(PC1^2) + I(PC2^2),
        family = binomial) |>
    predict(type = "response") |>
    {\(x) mean((x-S_prop)^2) / n_pMSE}()
  
  c(Synthpop = Synthpop_S_pMSE,
    Manual = Manual_S_pMSE)
})

PC <- pca(XR10, XS10)
R <- PC |> filter(Synthetic == "Real")
S <- PC |> filter(Synthetic == "Synthetic")


```

We see a clear discrepancy between the real and synthetic data in the figure, that is also reflected in the discrepancy score of the Kolmogorov-Smirnov test, but not in the logistic regression model (admittedly with only first order interaction terms and without squared terms, because that is not allowed by the software). If we include these terms, we find a very large standardized $pMSE$ value.

Of course, this finding makes sense, as we see that values that score high on the first principal component (in an absolute sense, so the values in the tails of the distribution) are more likely to be "real" values, whereas values that score high on the second principal component (in an absolute sense, again the values in the tails of the distribution) are much more likely to be synthetic records. However, this will only show up when considering the squared (or absolute) terms, because the centers of the distribution are at the same location for the real and synthetic data.


```{r}
map2(XR, XS, function(real, synthetic) {
  X <- rbind(real, synthetic)
  Y <- rep(c("Real", "Synthetic"), times = c(nrow(real), nrow(synthetic)))
  Z <- lfda(X, Y, r = ncol(X), metric = "orthonormalized")$Z |>
    data.frame() |>
    setNames(paste0("D", 1:ncol(real)))
  
  Z |>
    ggplot(aes(x = D1, y = D2, col = Y)) +
    geom_point(alpha = 0.5) +
    theme_minimal()
}) |>
  patchwork::wrap_plots(ncol = 3, guides = 'collect') &
  theme(legend.position = "bottom")
```

